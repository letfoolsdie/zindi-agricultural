{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import typing as tp\n",
    "import pathlib\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import cv2\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_speech_features as psf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>audio_files/IV38R7F.wav</td>\n",
       "      <td>akawuka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>audio_files/KM4SKWT.wav</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>audio_files/F5POSU9.wav</td>\n",
       "      <td>obulwadde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>audio_files/MMVDXG2.wav</td>\n",
       "      <td>nnyaanya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>audio_files/9TVM96F.wav</td>\n",
       "      <td>pampu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fn      label\n",
       "0  audio_files/IV38R7F.wav    akawuka\n",
       "1  audio_files/KM4SKWT.wav     banana\n",
       "2  audio_files/F5POSU9.wav  obulwadde\n",
       "3  audio_files/MMVDXG2.wav   nnyaanya\n",
       "4  audio_files/9TVM96F.wav      pampu"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(data_path/'Train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>audio_files_full/3d43af6faf2244c288154dc4ff6a7...</td>\n",
       "      <td>obuwuka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>audio_files_full/3d43af6faf2244c288154dc4ff6a7...</td>\n",
       "      <td>obuwuka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>audio_files_full/744b1a437234489fae9512694d221...</td>\n",
       "      <td>obuwuka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fn    label\n",
       "0  audio_files_full/3d43af6faf2244c288154dc4ff6a7...  obuwuka\n",
       "1  audio_files_full/3d43af6faf2244c288154dc4ff6a7...  obuwuka\n",
       "2  audio_files_full/744b1a437234489fae9512694d221...  obuwuka"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_extra = pd.read_csv(data_path/'train_add.csv')\n",
    "train_extra.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>audio_files_full_20201029/2497942026ef4d7e97d4...</td>\n",
       "      <td>obuwuka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>audio_files_full_20201029/d027264654b94950aeb2...</td>\n",
       "      <td>ejjobyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>audio_files_full_20201029/d027264654b94950aeb2...</td>\n",
       "      <td>ejjobyo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fn    label\n",
       "0  audio_files_full_20201029/2497942026ef4d7e97d4...  obuwuka\n",
       "1  audio_files_full_20201029/d027264654b94950aeb2...  ejjobyo\n",
       "2  audio_files_full_20201029/d027264654b94950aeb2...  ejjobyo"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_extra_2 = pd.read_csv(data_path/'train_add_20201029.csv')\n",
    "train_extra_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2code = {word: idx for idx, word in enumerate(train.label.unique().tolist())}\n",
    "code2label = {v:k for k,v in label2code.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios_path = data_path / \"all_audio_resampled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(audio_path):\n",
    "    file_name = audio_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    ip = str(audios_path.resolve() / f\"{file_name}.wav\")\n",
    "    return ip\n",
    "\n",
    "train[\"image_fn\"] = train.fn.apply(get_image_path)\n",
    "train_extra[\"image_fn\"] = train_extra.fn.apply(get_image_path)\n",
    "train_extra_2[\"image_fn\"] = train_extra_2.fn.apply(get_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train, train_extra], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build validation that includes all classes:\n",
    "\n",
    "\n",
    "vcs = train_df.label.value_counts()\n",
    "\n",
    "## possible schema:\n",
    "# 25+ - take 3\n",
    "# 12-25 - take 2\n",
    "# 12- - take 1\n",
    "\n",
    "def num_for_val(num_examples):\n",
    "    if num_examples >= 25:\n",
    "        return 3\n",
    "    if num_examples >= 12:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "train_df[\"num_examples\"] = train_df.label.map(vcs.to_dict())\n",
    "train_df[\"num_for_val\"] = train_df.num_examples.apply(num_for_val)\n",
    "\n",
    "random.seed(12)\n",
    "train_df_new = pd.DataFrame()\n",
    "for label in train_df.label.unique():\n",
    "    tmp = train_df.loc[train_df.label == label].copy()\n",
    "    tmp[\"dummy\"] = tmp.label.apply(lambda _: random.random())\n",
    "    tmp.sort_values(by=\"dummy\", inplace=True)\n",
    "    tmp[\"rank\"] = range(tmp.shape[0])\n",
    "    train_df_new = pd.concat([train_df_new, tmp])\n",
    "\n",
    "train_df_new.reset_index(drop=True, inplace=True)\n",
    "train_df_new[\"val_subset\"] = train_df_new.num_for_val > train_df_new[\"rank\"]\n",
    "train_df_new.drop(\"dummy\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    set(train_df_new.loc[train_df_new.val_subset].label.unique()) == \n",
    "    set(train_df_new.loc[~train_df_new.val_subset].label.unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 7)\n",
      "(349, 7)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_df_new.loc[~train_df_new.val_subset].copy(), train_df_new.loc[train_df_new.val_subset].copy()\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([\n",
    "    train_df.drop([\"num_examples\", \"num_for_val\", \"rank\", \"val_subset\"], axis=1),\n",
    "    train_extra_2\n",
    "]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4360, 3)\n",
      "(349, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check no val leaking\n",
    "assert train_df.merge(val_df, on=[\"image_fn\"], how=\"inner\").shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add part to make corrections to train & val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrs = pd.read_csv(data_path / \"2020_11_10_data_notes.tsv\", sep=\"\\t\", header=None)\n",
    "# corrs.columns = [\"fn\", \"original_label\", \"comment\", \"verdict\", \"stuff\", \"stuff_2\"]\n",
    "# corrs.fn = corrs.fn.apply(lambda x: x + \".wav\")\n",
    "\n",
    "# corrs = corrs.loc[corrs.verdict.isin({\"remove\", \"change label\"})].reset_index(drop=True).copy()\n",
    "# corrs[\"image_fn\"] = corrs.fn.apply(get_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.merge(corrs[[\"image_fn\", \"verdict\", \"stuff\"]], on=[\"image_fn\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm_mask = (train_df.verdict == \"remove\")\n",
    "# train_df = train_df.loc[~rm_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change_label = (train_df.verdict == \"change label\")\n",
    "# train_df.loc[change_label, \"label\"] = train_df.loc[change_label, \"stuff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df = val_df.merge(corrs[[\"image_fn\", \"verdict\", \"stuff\"]], on=[\"image_fn\"], how=\"left\").copy()\n",
    "# rm_mask = (val_df.verdict == \"remove\")\n",
    "# val_df_filt = val_df.loc[~rm_mask].copy()\n",
    "\n",
    "# print(val_df.shape)\n",
    "# print(val_df_filt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end part to make corrections to train & val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, trg=None):\n",
    "        if trg is None:\n",
    "            for t in self.transforms:\n",
    "                image = t(image)\n",
    "            return image\n",
    "        else:\n",
    "            for t in self.transforms:\n",
    "                image, trg = t(image, trg)\n",
    "            return image, trg\n",
    "\n",
    "\n",
    "class UseWithProb:\n",
    "    def __init__(self, transform, prob=.5):\n",
    "        self.transform = transform\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, image, trg=None):\n",
    "        if trg is None:\n",
    "            if random.random() < self.prob:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        else:\n",
    "            if random.random() < self.prob:\n",
    "                image, trg = self.transform(image, trg)\n",
    "            return image, trg\n",
    "\n",
    "\n",
    "class OneOf:\n",
    "    def __init__(self, transforms, p=None):\n",
    "        self.transforms = transforms\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, image, trg=None):\n",
    "        transform = np.random.choice(self.transforms, p=self.p)\n",
    "        if trg is None:\n",
    "            image = transform(image)\n",
    "            return image\n",
    "        else:\n",
    "            image, trg = transform(image, trg)\n",
    "            return image, trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchShift:\n",
    "    def __init__(self, pitch_range, sr=SR):\n",
    "        self.pr_low, self.pr_hi = pitch_range\n",
    "        self.sr=sr\n",
    "    \n",
    "    def __call__(self, audio):\n",
    "        shift = np.random.choice(np.linspace(self.pr_low, self.pr_hi, 100))\n",
    "        return librosa.effects.pitch_shift(audio, self.sr, shift)\n",
    "\n",
    "\n",
    "class TimeStretch:\n",
    "    def __init__(self, stretch_param):\n",
    "        self.stretch = stretch_param\n",
    "    \n",
    "    def __call__(self, audio):\n",
    "        \"\"\"\n",
    "        if self.stretch is one number, use it as stretch param.\n",
    "        if it's 2nums array, use it as limits for uniform distribution\n",
    "        from which we sample stretch param\n",
    "        \"\"\"\n",
    "        if type(self.stretch) in (int, float):\n",
    "            return librosa.effects.time_stretch(audio, self.stretch)\n",
    "        else:\n",
    "            low, hi = self.stretch\n",
    "            s = np.random.choice(np.linspace(low, hi, 100))\n",
    "            return librosa.effects.time_stretch(audio, s)\n",
    "        \n",
    "class AddNoise:\n",
    "    def __init__(self, loc, scale):\n",
    "        self.loc = loc\n",
    "        self.scale = scale\n",
    "        \n",
    "    def __call__(self, audio):\n",
    "        noise = np.random.normal(loc=self.loc, scale=self.scale, size=audio.shape)\n",
    "        return noise + audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_generate_spec(audio, config):\n",
    "    arr_limit = int(config.max_len_sec * config.sr)\n",
    "\n",
    "    # trim according to the config\n",
    "    if config.trim:\n",
    "        audio, trim_idx = librosa.effects.trim(audio)\n",
    "#     print(\"audio shape\", audio.shape)\n",
    "    # for long audios: trim:\n",
    "    if len(audio) >= arr_limit:\n",
    "        audio = audio[:arr_limit]\n",
    "    # for short: pad:\n",
    "    else:\n",
    "        \n",
    "        to_add = arr_limit - len(audio)\n",
    "        # pad either on the left:\n",
    "        if not config.pad_center:\n",
    "            audio = np.concatenate((np.zeros(to_add), audio))\n",
    "        # or on both sides (simmetrically):\n",
    "        else:\n",
    "            add_l = to_add // 2\n",
    "            add_r = to_add - add_l\n",
    "            audio = np.concatenate((np.zeros(add_l), audio, np.zeros(add_r)))\n",
    "    \n",
    "    X = librosa.stft(audio, n_fft=config.n_fft, hop_length=config.hop_size)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X), ref=np.max)\n",
    "    return Xdb\n",
    "\n",
    "\n",
    "def new_build_image(audio, config):\n",
    "    spec = new_generate_spec(audio, config)\n",
    "    \n",
    "    # Scale to (0, 255)\n",
    "    spec  -= spec.min()\n",
    "    spec *= 255.0/spec.max()\n",
    "\n",
    "    # Make it uint8\n",
    "    im_arr = np.array(spec, np.uint8)\n",
    "\n",
    "    # Make it rgb (hint - some fun tricks you can do here!)\n",
    "    r = im_arr\n",
    "    g = im_arr\n",
    "    b = im_arr\n",
    "    \n",
    "    image = np.stack([r, g, b], axis=-1)\n",
    "    image = cv2.resize(image, (config.img_size, config.img_size))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as tr\n",
    "from PIL import Image\n",
    "\n",
    "MEAN = np.array([0.485, 0.456, 0.406])\n",
    "STD = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def normalize(image, mean, std):\n",
    "    image = (image / 255.0).astype(np.float32)\n",
    "    image = (image - mean) / std\n",
    "    return image\n",
    "\n",
    "class SpectrogramDataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_list: tp.List[tp.List[str]],\n",
    "        config,\n",
    "        transform=None,\n",
    "        normalize=True\n",
    "    ):\n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "#         self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.normalize = normalize\n",
    "#         self.audios_dict = audios_dict\n",
    "        self.config = config\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        fn, word = self.file_list[idx]\n",
    "        audio, _ = librosa.core.load(fn, sr=SR)\n",
    "#         audio = self.audios_dict[fn]\n",
    "\n",
    "        if self.transform:\n",
    "            audio = self.transform(audio)\n",
    "\n",
    "        image = new_build_image(audio, self.config)\n",
    "        \n",
    "        if self.normalize:\n",
    "            norm_image = normalize(np.array(image), mean=MEAN, std=STD)\n",
    "        else:\n",
    "            norm_image = image\n",
    "        \n",
    "        return np.moveaxis(norm_image, 2, 0), label2code[word]\n",
    "    \n",
    "    \n",
    "class SpectrogramTestDataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_list: tp.List[tp.List[str]],\n",
    "        config,\n",
    "        transform=None,\n",
    "        normalize=True\n",
    "    ):\n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "#         self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.normalize = normalize\n",
    "#         self.audios_dict = audios_dict\n",
    "        self.config = config\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        fn, word = self.file_list[idx]\n",
    "        audio, _ = librosa.core.load(fn, sr=SR)\n",
    "#         audio = self.audios_dict[fn]\n",
    "\n",
    "        if self.transform:\n",
    "            audio = self.transform(audio)\n",
    "\n",
    "        image = new_build_image(audio, self.config)\n",
    "        \n",
    "        if self.normalize:\n",
    "            norm_image = normalize(np.array(image), mean=MEAN, std=STD)\n",
    "        else:\n",
    "            norm_image = image\n",
    "        \n",
    "        return np.moveaxis(norm_image, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as tr\n",
    "\n",
    "\n",
    "# aug_noise = AddNoise(0, 0.07)\n",
    "# aug_ts = TimeStretch((0.5, 2))\n",
    "# aug_pitch = PitchShift((-5, 5))\n",
    "\n",
    "# train_transforms = OneOf([\n",
    "#     aug_noise,\n",
    "#     aug_ts,\n",
    "#     aug_pitch\n",
    "# ])\n",
    "\n",
    "class AudioConfig:\n",
    "    n_fft = 1024\n",
    "    hop_size = 256\n",
    "    pad_center = True\n",
    "    trim = True\n",
    "    max_len_sec = 3 #1 if trim else 2.5\n",
    "    sr = 22050\n",
    "    img_size = 299\n",
    "    \n",
    "conf = AudioConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_train = SpectrogramDataset(train_df[[\"image_fn\", \"label\"]].values.tolist(), conf, normalize=True)\n",
    "sdf_val = SpectrogramDataset(val_df[[\"image_fn\", \"label\"]].values.tolist(), conf, normalize=True)\n",
    "# sdf_val_filt = SpectrogramDataset(val_df_filt[[\"image_fn\", \"label\"]].values.tolist(), conf, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/mhiro2/simple-2d-cnn-classifier-with-pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleKaggle(nn.Module):\n",
    "    def __init__(self, num_classes, base_size=64, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            ConvBlock(in_channels=3, out_channels=base_size),\n",
    "            ConvBlock(in_channels=base_size, out_channels=base_size*2),\n",
    "            ConvBlock(in_channels=base_size*2, out_channels=base_size*4),\n",
    "            ConvBlock(in_channels=base_size*4, out_channels=base_size*8),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_size*8, base_size*2),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(base_size*2),\n",
    "            nn.Dropout(dropout/2),\n",
    "            nn.Linear(base_size*2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        x, _ = torch.max(x, dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# model_ft = models.resnet101(pretrained=True)\n",
    "# model_ft = models.resnet50(pretrained=True)\n",
    "# print(model_ft.fc.in_features)\n",
    "\n",
    "n_classes = len(label2code)\n",
    "\n",
    "# model_ft.fc = nn.Sequential(\n",
    "#     nn.Linear(model_ft.fc.in_features, n_classes)\n",
    "# )\n",
    "model_ft = SimpleKaggle(n_classes)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer_ft, 'min', patience=4, factor=0.5, verbose=True, min_lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(log_interval, model, device, criterion, train_loader, optimizer, epoch):\n",
    "#     print(epoch)\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.type(torch.FloatTensor).to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return loss.item()\n",
    "\n",
    "            \n",
    "def test(model, device, criterion, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.type(torch.FloatTensor).to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(sdf_train, batch_size=32, shuffle=True,\n",
    "                                           num_workers=4, drop_last=False, pin_memory=True) ## ADDED shuffle\n",
    "val_loader = torch.utils.data.DataLoader(sdf_val, batch_size=32, drop_last=False, pin_memory=True)\n",
    "# val_filt_loader = torch.utils.data.DataLoader(sdf_val_filt, batch_size=32, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 5.3282, Accuracy: 3/349 (1%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.328178821115576, 0.8595988538681948)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model_ft, device, criterion, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(model_ft, device, criterion, val_filt_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/4360 (0%)]\tLoss: 176.974762\n",
      "\n",
      "Test set: Average loss: 5.2703, Accuracy: 8/349 (2%)\n",
      "\n",
      "Training so far 1.1458705186843872 minutes\n",
      "====================\n",
      "Train Epoch: 1 [0/4360 (0%)]\tLoss: 154.253250\n",
      "\n",
      "Test set: Average loss: 4.7784, Accuracy: 20/349 (6%)\n",
      "\n",
      "Training so far 2.2870932777722675 minutes\n",
      "====================\n",
      "Train Epoch: 2 [0/4360 (0%)]\tLoss: 144.406921\n",
      "\n",
      "Test set: Average loss: 4.5467, Accuracy: 23/349 (7%)\n",
      "\n",
      "Training so far 3.436076537768046 minutes\n",
      "====================\n",
      "Train Epoch: 3 [0/4360 (0%)]\tLoss: 132.129654\n",
      "\n",
      "Test set: Average loss: 4.3442, Accuracy: 49/349 (14%)\n",
      "\n",
      "Training so far 4.587446661790212 minutes\n",
      "====================\n",
      "Train Epoch: 4 [0/4360 (0%)]\tLoss: 117.118752\n",
      "\n",
      "Test set: Average loss: 3.9349, Accuracy: 62/349 (18%)\n",
      "\n",
      "Training so far 5.74212201833725 minutes\n",
      "====================\n",
      "Train Epoch: 5 [0/4360 (0%)]\tLoss: 107.053726\n",
      "\n",
      "Test set: Average loss: 3.3750, Accuracy: 111/349 (32%)\n",
      "\n",
      "Training so far 6.897589282194773 minutes\n",
      "====================\n",
      "Train Epoch: 6 [0/4360 (0%)]\tLoss: 83.427567\n",
      "\n",
      "Test set: Average loss: 3.2950, Accuracy: 129/349 (37%)\n",
      "\n",
      "Training so far 8.049570802847544 minutes\n",
      "====================\n",
      "Train Epoch: 7 [0/4360 (0%)]\tLoss: 72.598549\n",
      "\n",
      "Test set: Average loss: 2.9012, Accuracy: 152/349 (44%)\n",
      "\n",
      "Training so far 9.201752241452535 minutes\n",
      "====================\n",
      "Train Epoch: 8 [0/4360 (0%)]\tLoss: 64.430641\n",
      "\n",
      "Test set: Average loss: 2.8256, Accuracy: 146/349 (42%)\n",
      "\n",
      "Training so far 10.357618749141693 minutes\n",
      "====================\n",
      "Train Epoch: 9 [0/4360 (0%)]\tLoss: 59.647751\n",
      "\n",
      "Test set: Average loss: 2.5081, Accuracy: 175/349 (50%)\n",
      "\n",
      "Training so far 11.512578733762105 minutes\n",
      "====================\n",
      "Train Epoch: 10 [0/4360 (0%)]\tLoss: 52.057632\n",
      "\n",
      "Test set: Average loss: 2.4562, Accuracy: 187/349 (54%)\n",
      "\n",
      "Training so far 12.667709314823151 minutes\n",
      "====================\n",
      "Train Epoch: 11 [0/4360 (0%)]\tLoss: 50.911072\n",
      "\n",
      "Test set: Average loss: 2.1883, Accuracy: 200/349 (57%)\n",
      "\n",
      "Training so far 13.820428737004598 minutes\n",
      "====================\n",
      "Train Epoch: 12 [0/4360 (0%)]\tLoss: 37.231956\n",
      "\n",
      "Test set: Average loss: 2.2018, Accuracy: 193/349 (55%)\n",
      "\n",
      "patience: 1\n",
      "Training so far 14.972580846150716 minutes\n",
      "====================\n",
      "Train Epoch: 13 [0/4360 (0%)]\tLoss: 27.715353\n",
      "\n",
      "Test set: Average loss: 1.8997, Accuracy: 206/349 (59%)\n",
      "\n",
      "Training so far 16.130200997988382 minutes\n",
      "====================\n",
      "Train Epoch: 14 [0/4360 (0%)]\tLoss: 22.637497\n",
      "\n",
      "Test set: Average loss: 1.6826, Accuracy: 229/349 (66%)\n",
      "\n",
      "Training so far 17.28180179198583 minutes\n",
      "====================\n",
      "Train Epoch: 15 [0/4360 (0%)]\tLoss: 23.307631\n",
      "\n",
      "Test set: Average loss: 1.9284, Accuracy: 211/349 (60%)\n",
      "\n",
      "patience: 1\n",
      "Training so far 18.43602454662323 minutes\n",
      "====================\n",
      "Train Epoch: 16 [0/4360 (0%)]\tLoss: 16.218079\n",
      "\n",
      "Test set: Average loss: 1.5071, Accuracy: 231/349 (66%)\n",
      "\n",
      "Training so far 19.592543522516888 minutes\n",
      "====================\n",
      "Train Epoch: 17 [0/4360 (0%)]\tLoss: 25.318354\n",
      "\n",
      "Test set: Average loss: 1.4697, Accuracy: 246/349 (70%)\n",
      "\n",
      "Training so far 20.747429752349852 minutes\n",
      "====================\n",
      "Train Epoch: 18 [0/4360 (0%)]\tLoss: 18.074007\n",
      "\n",
      "Test set: Average loss: 1.3489, Accuracy: 244/349 (70%)\n",
      "\n",
      "Training so far 21.900748534997305 minutes\n",
      "====================\n",
      "Train Epoch: 19 [0/4360 (0%)]\tLoss: 13.654000\n",
      "\n",
      "Test set: Average loss: 1.3747, Accuracy: 248/349 (71%)\n",
      "\n",
      "patience: 1\n",
      "Training so far 23.054076643784843 minutes\n",
      "====================\n",
      "Train Epoch: 20 [0/4360 (0%)]\tLoss: 7.819121\n",
      "\n",
      "Test set: Average loss: 1.1974, Accuracy: 260/349 (74%)\n",
      "\n",
      "Training so far 24.213087093830108 minutes\n",
      "====================\n",
      "Train Epoch: 21 [0/4360 (0%)]\tLoss: 6.137573\n",
      "\n",
      "Test set: Average loss: 1.3005, Accuracy: 247/349 (71%)\n",
      "\n",
      "patience: 1\n",
      "Training so far 25.36665980021159 minutes\n",
      "====================\n",
      "Train Epoch: 22 [0/4360 (0%)]\tLoss: 13.064736\n",
      "\n",
      "Test set: Average loss: 1.1347, Accuracy: 265/349 (76%)\n",
      "\n",
      "Training so far 26.524664656321207 minutes\n",
      "====================\n",
      "Train Epoch: 23 [0/4360 (0%)]\tLoss: 5.482700\n",
      "\n",
      "Test set: Average loss: 1.1448, Accuracy: 263/349 (75%)\n",
      "\n",
      "patience: 1\n",
      "Training so far 27.67917348941167 minutes\n",
      "====================\n",
      "Train Epoch: 24 [0/4360 (0%)]\tLoss: 4.888556\n",
      "\n",
      "Test set: Average loss: 1.1632, Accuracy: 259/349 (74%)\n",
      "\n",
      "patience: 2\n",
      "Training so far 28.83650727669398 minutes\n",
      "====================\n",
      "Train Epoch: 25 [0/4360 (0%)]\tLoss: 6.084772\n",
      "\n",
      "Test set: Average loss: 1.1844, Accuracy: 256/349 (73%)\n",
      "\n",
      "patience: 3\n",
      "Training so far 29.993049188454947 minutes\n",
      "====================\n",
      "Train Epoch: 26 [0/4360 (0%)]\tLoss: 5.027719\n",
      "\n",
      "Test set: Average loss: 1.0562, Accuracy: 265/349 (76%)\n",
      "\n",
      "Training so far 31.175246779123942 minutes\n",
      "====================\n",
      "Train Epoch: 27 [0/4360 (0%)]\tLoss: 6.303385\n",
      "\n",
      "Test set: Average loss: 0.9694, Accuracy: 274/349 (79%)\n",
      "\n",
      "Training so far 32.32833149433136 minutes\n",
      "====================\n",
      "Train Epoch: 28 [0/4360 (0%)]\tLoss: 3.955576\n",
      "\n",
      "Test set: Average loss: 0.9813, Accuracy: 273/349 (78%)\n",
      "\n",
      "patience: 1\n",
      "Training so far 33.480895260969795 minutes\n",
      "====================\n",
      "Train Epoch: 29 [0/4360 (0%)]\tLoss: 2.045704\n",
      "\n",
      "Test set: Average loss: 1.0923, Accuracy: 267/349 (77%)\n",
      "\n",
      "patience: 2\n",
      "Training so far 34.63679496049881 minutes\n",
      "====================\n",
      "Train Epoch: 30 [0/4360 (0%)]\tLoss: 1.938088\n",
      "\n",
      "Test set: Average loss: 1.0520, Accuracy: 262/349 (75%)\n",
      "\n",
      "patience: 3\n",
      "Training so far 35.7926681637764 minutes\n",
      "====================\n",
      "Train Epoch: 31 [0/4360 (0%)]\tLoss: 2.090010\n",
      "\n",
      "Test set: Average loss: 1.0018, Accuracy: 271/349 (78%)\n",
      "\n",
      "patience: 4\n",
      "Training so far 36.9472242196401 minutes\n",
      "====================\n",
      "Train Epoch: 32 [0/4360 (0%)]\tLoss: 2.430243\n",
      "\n",
      "Test set: Average loss: 1.0415, Accuracy: 262/349 (75%)\n",
      "\n",
      "patience: 5\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Training so far 38.104098947842914 minutes\n",
      "====================\n",
      "Train Epoch: 33 [0/4360 (0%)]\tLoss: 3.946545\n",
      "\n",
      "Test set: Average loss: 0.8883, Accuracy: 282/349 (81%)\n",
      "\n",
      "Training so far 39.259973307450615 minutes\n",
      "====================\n",
      "Train Epoch: 34 [0/4360 (0%)]\tLoss: 1.464607\n",
      "\n",
      "Test set: Average loss: 0.8777, Accuracy: 278/349 (80%)\n",
      "\n",
      "Training so far 40.41399235725403 minutes\n",
      "====================\n",
      "Train Epoch: 35 [0/4360 (0%)]\tLoss: 1.035053\n",
      "\n",
      "Test set: Average loss: 0.8707, Accuracy: 278/349 (80%)\n",
      "\n",
      "Training so far 41.56695323785146 minutes\n",
      "====================\n",
      "Train Epoch: 36 [0/4360 (0%)]\tLoss: 0.385955\n",
      "\n",
      "Test set: Average loss: 0.8632, Accuracy: 280/349 (80%)\n",
      "\n",
      "Training so far 42.72185864051183 minutes\n",
      "====================\n",
      "Train Epoch: 37 [0/4360 (0%)]\tLoss: 1.018612\n",
      "\n",
      "Test set: Average loss: 0.8579, Accuracy: 283/349 (81%)\n",
      "\n",
      "Training so far 43.87589973608653 minutes\n",
      "====================\n",
      "Train Epoch: 38 [0/4360 (0%)]\tLoss: 0.440987\n",
      "\n",
      "Test set: Average loss: 0.8595, Accuracy: 279/349 (80%)\n",
      "\n",
      "patience: 1\n",
      "Training so far 45.02790752251943 minutes\n",
      "====================\n",
      "Train Epoch: 39 [0/4360 (0%)]\tLoss: 0.345433\n",
      "\n",
      "Test set: Average loss: 0.8491, Accuracy: 284/349 (81%)\n",
      "\n",
      "Training so far 46.185258408387504 minutes\n",
      "====================\n",
      "Train Epoch: 40 [0/4360 (0%)]\tLoss: 0.395761\n",
      "\n",
      "Test set: Average loss: 0.8394, Accuracy: 284/349 (81%)\n",
      "\n",
      "Training so far 47.3383745710055 minutes\n",
      "====================\n",
      "Train Epoch: 41 [0/4360 (0%)]\tLoss: 0.521287\n",
      "\n",
      "Test set: Average loss: 0.8340, Accuracy: 285/349 (82%)\n",
      "\n",
      "Training so far 48.49294584592183 minutes\n",
      "====================\n",
      "Train Epoch: 42 [0/4360 (0%)]\tLoss: 0.350267\n",
      "\n",
      "Test set: Average loss: 0.8480, Accuracy: 283/349 (81%)\n",
      "\n",
      "patience: 1\n",
      "Training so far 49.64490671952566 minutes\n",
      "====================\n",
      "Train Epoch: 43 [0/4360 (0%)]\tLoss: 0.416338\n",
      "\n",
      "Test set: Average loss: 0.8375, Accuracy: 283/349 (81%)\n",
      "\n",
      "patience: 2\n",
      "Training so far 50.79889755646388 minutes\n",
      "====================\n",
      "Train Epoch: 44 [0/4360 (0%)]\tLoss: 0.335544\n",
      "\n",
      "Test set: Average loss: 0.8673, Accuracy: 280/349 (80%)\n",
      "\n",
      "patience: 3\n",
      "Training so far 51.95434071222941 minutes\n",
      "====================\n",
      "Train Epoch: 45 [0/4360 (0%)]\tLoss: 0.266848\n",
      "\n",
      "Test set: Average loss: 0.8515, Accuracy: 281/349 (81%)\n",
      "\n",
      "patience: 4\n",
      "Training so far 53.11034591595332 minutes\n",
      "====================\n",
      "Train Epoch: 46 [0/4360 (0%)]\tLoss: 0.270349\n",
      "\n",
      "Test set: Average loss: 0.8390, Accuracy: 281/349 (81%)\n",
      "\n",
      "patience: 5\n",
      "Epoch    47: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Training so far 54.26738886435827 minutes\n",
      "====================\n",
      "Train Epoch: 47 [0/4360 (0%)]\tLoss: 0.450068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8365, Accuracy: 284/349 (81%)\n",
      "\n",
      "patience: 6\n",
      "Training so far 55.42299674749374 minutes\n",
      "====================\n",
      "Train Epoch: 48 [0/4360 (0%)]\tLoss: 0.242958\n",
      "\n",
      "Test set: Average loss: 0.8343, Accuracy: 285/349 (82%)\n",
      "\n",
      "patience: 7\n",
      "Training so far 56.57912106513977 minutes\n",
      "====================\n",
      "Train Epoch: 49 [0/4360 (0%)]\tLoss: 0.233240\n",
      "\n",
      "Test set: Average loss: 0.8445, Accuracy: 281/349 (81%)\n",
      "\n",
      "patience: 8\n",
      "Training so far 57.7353971362114 minutes\n",
      "====================\n",
      "Train Epoch: 50 [0/4360 (0%)]\tLoss: 0.281996\n",
      "\n",
      "Test set: Average loss: 0.8433, Accuracy: 283/349 (81%)\n",
      "\n",
      "patience: 9\n",
      "Training so far 58.89131880203883 minutes\n",
      "====================\n",
      "Train Epoch: 51 [0/4360 (0%)]\tLoss: 0.211189\n",
      "\n",
      "Test set: Average loss: 0.8367, Accuracy: 283/349 (81%)\n",
      "\n",
      "patience: 10\n",
      "Epoch    52: reducing learning rate of group 0 to 3.0000e-05.\n",
      "Training so far 60.04624349276225 minutes\n",
      "====================\n",
      "Train Epoch: 52 [0/4360 (0%)]\tLoss: 0.212462\n",
      "\n",
      "Test set: Average loss: 0.8361, Accuracy: 282/349 (81%)\n",
      "\n",
      "patience: 11\n",
      "Training so far 61.20140066544215 minutes\n",
      "====================\n",
      "Train Epoch: 53 [0/4360 (0%)]\tLoss: 0.184269\n",
      "\n",
      "Test set: Average loss: 0.8405, Accuracy: 279/349 (80%)\n",
      "\n",
      "patience: 12\n",
      "Training so far 62.35891632636388 minutes\n",
      "====================\n",
      "Train Epoch: 54 [0/4360 (0%)]\tLoss: 0.166053\n",
      "\n",
      "Test set: Average loss: 0.8395, Accuracy: 282/349 (81%)\n",
      "\n",
      "patience: 13\n",
      "Training so far 63.51778859694799 minutes\n",
      "====================\n",
      "Train Epoch: 55 [0/4360 (0%)]\tLoss: 0.335425\n",
      "\n",
      "Test set: Average loss: 0.8380, Accuracy: 282/349 (81%)\n",
      "\n",
      "patience: 14\n",
      "Training so far 64.67677083412806 minutes\n",
      "====================\n",
      "Train Epoch: 56 [0/4360 (0%)]\tLoss: 0.148121\n",
      "\n",
      "Test set: Average loss: 0.8475, Accuracy: 285/349 (82%)\n",
      "\n",
      "patience: 15\n",
      "Training so far 65.83443500995637 minutes\n",
      "====================\n",
      "Train Epoch: 57 [0/4360 (0%)]\tLoss: 0.256346\n",
      "\n",
      "Test set: Average loss: 0.8483, Accuracy: 285/349 (82%)\n",
      "\n",
      "patience: 16\n",
      "Training so far 66.99207337299983 minutes\n",
      "====================\n",
      "Train Epoch: 58 [0/4360 (0%)]\tLoss: 0.168508\n",
      "\n",
      "Test set: Average loss: 0.8394, Accuracy: 283/349 (81%)\n",
      "\n",
      "patience: 17\n",
      "Training so far 68.147473971049 minutes\n",
      "====================\n",
      "Train Epoch: 59 [0/4360 (0%)]\tLoss: 0.132042\n",
      "\n",
      "Test set: Average loss: 0.8472, Accuracy: 283/349 (81%)\n",
      "\n",
      "patience: 18\n",
      "Training so far 69.30367303291956 minutes\n",
      "====================\n",
      "Train Epoch: 60 [0/4360 (0%)]\tLoss: 0.109049\n",
      "\n",
      "Test set: Average loss: 0.8454, Accuracy: 283/349 (81%)\n",
      "\n",
      "patience: 19\n",
      "Training so far 70.45955904324849 minutes\n",
      "====================\n",
      "Train Epoch: 61 [0/4360 (0%)]\tLoss: 0.100049\n",
      "\n",
      "Test set: Average loss: 0.8433, Accuracy: 283/349 (81%)\n",
      "\n",
      "patience: 20\n",
      "Training so far 71.61796001593272 minutes\n",
      "====================\n",
      "Train Epoch: 62 [0/4360 (0%)]\tLoss: 0.135087\n",
      "\n",
      "Test set: Average loss: 0.8492, Accuracy: 282/349 (81%)\n",
      "\n",
      "patience: 21\n",
      "Training so far 72.77393365303675 minutes\n",
      "====================\n",
      "Train Epoch: 63 [0/4360 (0%)]\tLoss: 0.195318\n",
      "\n",
      "Test set: Average loss: 0.8358, Accuracy: 288/349 (83%)\n",
      "\n",
      "patience: 22\n",
      "Training so far 73.93194372256598 minutes\n",
      "====================\n",
      "Train Epoch: 64 [0/4360 (0%)]\tLoss: 0.214709\n",
      "\n",
      "Test set: Average loss: 0.8323, Accuracy: 279/349 (80%)\n",
      "\n",
      "Training so far 75.08896299997966 minutes\n",
      "====================\n",
      "Train Epoch: 65 [0/4360 (0%)]\tLoss: 0.130846\n",
      "\n",
      "Test set: Average loss: 0.8305, Accuracy: 285/349 (82%)\n",
      "\n",
      "Training so far 76.24414995114009 minutes\n",
      "====================\n",
      "Train Epoch: 66 [0/4360 (0%)]\tLoss: 0.130099\n",
      "\n",
      "Test set: Average loss: 0.8446, Accuracy: 282/349 (81%)\n",
      "\n",
      "patience: 1\n",
      "Training so far 77.39750731786093 minutes\n",
      "====================\n",
      "Train Epoch: 67 [0/4360 (0%)]\tLoss: 0.125289\n",
      "\n",
      "Test set: Average loss: 0.8415, Accuracy: 283/349 (81%)\n",
      "\n",
      "patience: 2\n",
      "Training so far 78.554405828317 minutes\n",
      "====================\n",
      "Train Epoch: 68 [0/4360 (0%)]\tLoss: 0.148317\n",
      "\n",
      "Test set: Average loss: 0.8414, Accuracy: 277/349 (79%)\n",
      "\n",
      "patience: 3\n",
      "Training so far 79.71048667430878 minutes\n",
      "====================\n",
      "Train Epoch: 69 [0/4360 (0%)]\tLoss: 0.221419\n",
      "\n",
      "Test set: Average loss: 0.8621, Accuracy: 279/349 (80%)\n",
      "\n",
      "patience: 4\n",
      "Training so far 80.86645688613255 minutes\n",
      "====================\n",
      "Train Epoch: 70 [0/4360 (0%)]\tLoss: 0.310185\n",
      "\n",
      "Test set: Average loss: 0.8371, Accuracy: 284/349 (81%)\n",
      "\n",
      "patience: 5\n",
      "Training so far 82.02161164681117 minutes\n",
      "====================\n",
      "Train Epoch: 71 [0/4360 (0%)]\tLoss: 0.105743\n",
      "\n",
      "Test set: Average loss: 0.8289, Accuracy: 285/349 (82%)\n",
      "\n",
      "Training so far 83.17901268402736 minutes\n",
      "====================\n",
      "Train Epoch: 72 [0/4360 (0%)]\tLoss: 0.081434\n",
      "\n",
      "Test set: Average loss: 0.8367, Accuracy: 285/349 (82%)\n",
      "\n",
      "patience: 1\n",
      "Training so far 84.33389332294465 minutes\n",
      "====================\n",
      "Train Epoch: 73 [0/4360 (0%)]\tLoss: 0.111813\n",
      "\n",
      "Test set: Average loss: 0.8307, Accuracy: 283/349 (81%)\n",
      "\n",
      "patience: 2\n",
      "Training so far 85.49056499799093 minutes\n",
      "====================\n",
      "Train Epoch: 74 [0/4360 (0%)]\tLoss: 0.145630\n",
      "\n",
      "Test set: Average loss: 0.8297, Accuracy: 283/349 (81%)\n",
      "\n",
      "patience: 3\n",
      "Training so far 86.6466626683871 minutes\n",
      "====================\n",
      "time spent training: 86.64666499296824 minutes\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "tmp_folder_name = \"REPR_simple_kaggle_spec_exp\"\n",
    "\n",
    "best_loss = 1e5\n",
    "best_acc = 0\n",
    "\n",
    "max_patience = 20\n",
    "patience = 0\n",
    "os.mkdir(f\"tmp/{tmp_folder_name}\")\n",
    "\n",
    "train_loss_hist = list()\n",
    "val_loss_hist = list()\n",
    "val_acc_hist = list()\n",
    "# val_loss_hist_filt = list()\n",
    "# val_acc_hist_filt = list()\n",
    "\n",
    "save_each_epoch = False\n",
    "\n",
    "set_seed(9)\n",
    "\n",
    "\n",
    "for ep in range(75):\n",
    "    train_loss = train_epoch(1e10, model_ft, device, criterion, train_loader, optimizer_ft, ep)\n",
    "    cur_loss, cur_acc = test(model_ft, device, criterion, val_loader)\n",
    "    \n",
    "    train_loss_hist.append(train_loss)\n",
    "    val_loss_hist.append(cur_loss)\n",
    "    val_acc_hist.append(cur_acc)\n",
    "    \n",
    "    if save_each_epoch:\n",
    "        torch.save(model_ft.state_dict(), f\"tmp/{tmp_folder_name}/model_ep_{ep}.pth\")\n",
    "\n",
    "    if cur_loss < best_loss:\n",
    "        torch.save(model_ft.state_dict(), f\"tmp/{tmp_folder_name}/best_run.pth\")\n",
    "        best_loss = cur_loss\n",
    "        best_acc = cur_acc\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        print(\"patience:\", patience)\n",
    "#         if patience > max_patience:\n",
    "#             break\n",
    "\n",
    "    lr_scheduler.step(cur_loss) ## removed lr scheduler for now\n",
    "    print(\"Training so far {} minutes\".format((time.time() - t0) / 60))\n",
    "    print(\"=\"*20)\n",
    "\n",
    "print(\"time spent training: {} minutes\".format((time.time() - t0) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"time spent training: {} minutes\".format((time.time() - t0) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model_ft.state_dict(), f\"tmp/{tmp_folder_name}/model_ep_{ep}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828887540494815\n",
      "0.828887540494815\n"
     ]
    }
   ],
   "source": [
    "# torch.save(model_ft.state_dict(), f\"resnet18_ep30.pth\")\n",
    "print(min(val_loss_hist))\n",
    "print(best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REPR_simple_kaggle_spec_exp'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8252148997134671\n",
      "0.816618911174785\n"
     ]
    }
   ],
   "source": [
    "print(max(val_acc_hist) / 100)\n",
    "print(best_acc / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f832a990860>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(val_loss_hist)), val_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f832a710fd0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(val_acc_hist)), val_acc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8321d42dd8>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_loss_hist)), train_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.load_state_dict(torch.load(f\"tmp/{tmp_folder_name}/best_run.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try inference:\n",
    "test_loader = torch.utils.data.DataLoader(sdf_val, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/letfoolsdie/virtual_envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.52 s, sys: 194 ms, total: 4.72 s\n",
      "Wall time: 3.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sfm = nn.Softmax()\n",
    "predictions = list()\n",
    "\n",
    "for batch_idx, (inputs, _) in enumerate(test_loader):\n",
    "    inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model_ft(inputs)\n",
    "        predictions.append(sfm(outputs)) ## ADD SOFTMAX\n",
    "\n",
    "predictions = np.concatenate([t.cpu().numpy() for t in predictions])\n",
    "preds = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"preds\"] = [code2label[c] for c in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166189111747851"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_df.label == val_df.preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>maize streak virus</th>\n",
       "      <th>disease</th>\n",
       "      <th>okukkoola</th>\n",
       "      <th>muwogo</th>\n",
       "      <th>mpeke</th>\n",
       "      <th>mucungwa</th>\n",
       "      <th>greens</th>\n",
       "      <th>garden</th>\n",
       "      <th>mango</th>\n",
       "      <th>...</th>\n",
       "      <th>kasaanyi</th>\n",
       "      <th>suckers</th>\n",
       "      <th>insects</th>\n",
       "      <th>fertilizer</th>\n",
       "      <th>nakavundira</th>\n",
       "      <th>ekiwojjolo</th>\n",
       "      <th>akawuka</th>\n",
       "      <th>ddagala</th>\n",
       "      <th>ebiwojjolo</th>\n",
       "      <th>obutungulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>audio_files/00118N3.wav</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>audio_files/00P0NMV.wav</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.218384</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.026944</td>\n",
       "      <td>0.014598</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.004125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>audio_files/01QEEZI.wav</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.001558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fn  maize streak virus   disease  okukkoola    muwogo  \\\n",
       "0  audio_files/00118N3.wav            0.002769  0.002084   0.005227  0.002884   \n",
       "1  audio_files/00P0NMV.wav            0.001113  0.006091   0.001480  0.005104   \n",
       "2  audio_files/01QEEZI.wav            0.001245  0.003642   0.001077  0.005952   \n",
       "\n",
       "      mpeke  mucungwa    greens    garden     mango  ...  kasaanyi   suckers  \\\n",
       "0  0.004507  0.003533  0.001687  0.001626  0.003026  ...  0.001507  0.002586   \n",
       "1  0.004039  0.001252  0.000326  0.009214  0.000750  ...  0.002991  0.001708   \n",
       "2  0.006379  0.003655  0.002700  0.002457  0.000995  ...  0.007273  0.005435   \n",
       "\n",
       "    insects  fertilizer  nakavundira  ekiwojjolo   akawuka   ddagala  \\\n",
       "0  0.000081    0.000787     0.001928    0.004070  0.000132  0.000324   \n",
       "1  0.001014    0.000887     0.218384    0.002322  0.026944  0.014598   \n",
       "2  0.000962    0.002200     0.001465    0.001184  0.000905  0.000909   \n",
       "\n",
       "   ebiwojjolo  obutungulu  \n",
       "0    0.003241    0.003494  \n",
       "1    0.005134    0.004125  \n",
       "2    0.000670    0.001558  \n",
       "\n",
       "[3 rows x 194 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_subm = pd.read_csv(\"Submission1.csv\")\n",
    "sample_subm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_subm[\"image_fn\"] = sample_subm.fn.apply(get_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>maize streak virus</th>\n",
       "      <th>disease</th>\n",
       "      <th>okukkoola</th>\n",
       "      <th>muwogo</th>\n",
       "      <th>mpeke</th>\n",
       "      <th>mucungwa</th>\n",
       "      <th>greens</th>\n",
       "      <th>garden</th>\n",
       "      <th>mango</th>\n",
       "      <th>...</th>\n",
       "      <th>suckers</th>\n",
       "      <th>insects</th>\n",
       "      <th>fertilizer</th>\n",
       "      <th>nakavundira</th>\n",
       "      <th>ekiwojjolo</th>\n",
       "      <th>akawuka</th>\n",
       "      <th>ddagala</th>\n",
       "      <th>ebiwojjolo</th>\n",
       "      <th>obutungulu</th>\n",
       "      <th>image_fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>audio_files/00118N3.wav</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>/home/letfoolsdie/zindi_nlp/data/all_audio_res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>audio_files/00P0NMV.wav</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.218384</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.026944</td>\n",
       "      <td>0.014598</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>/home/letfoolsdie/zindi_nlp/data/all_audio_res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>audio_files/01QEEZI.wav</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>/home/letfoolsdie/zindi_nlp/data/all_audio_res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fn  maize streak virus   disease  okukkoola    muwogo  \\\n",
       "0  audio_files/00118N3.wav            0.002769  0.002084   0.005227  0.002884   \n",
       "1  audio_files/00P0NMV.wav            0.001113  0.006091   0.001480  0.005104   \n",
       "2  audio_files/01QEEZI.wav            0.001245  0.003642   0.001077  0.005952   \n",
       "\n",
       "      mpeke  mucungwa    greens    garden     mango  ...   suckers   insects  \\\n",
       "0  0.004507  0.003533  0.001687  0.001626  0.003026  ...  0.002586  0.000081   \n",
       "1  0.004039  0.001252  0.000326  0.009214  0.000750  ...  0.001708  0.001014   \n",
       "2  0.006379  0.003655  0.002700  0.002457  0.000995  ...  0.005435  0.000962   \n",
       "\n",
       "   fertilizer  nakavundira  ekiwojjolo   akawuka   ddagala  ebiwojjolo  \\\n",
       "0    0.000787     0.001928    0.004070  0.000132  0.000324    0.003241   \n",
       "1    0.000887     0.218384    0.002322  0.026944  0.014598    0.005134   \n",
       "2    0.002200     0.001465    0.001184  0.000905  0.000909    0.000670   \n",
       "\n",
       "   obutungulu                                           image_fn  \n",
       "0    0.003494  /home/letfoolsdie/zindi_nlp/data/all_audio_res...  \n",
       "1    0.004125  /home/letfoolsdie/zindi_nlp/data/all_audio_res...  \n",
       "2    0.001558  /home/letfoolsdie/zindi_nlp/data/all_audio_res...  \n",
       "\n",
       "[3 rows x 195 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_subm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, test_loader):\n",
    "    sfm = nn.Softmax()\n",
    "    predictions = list()\n",
    "    for batch_idx, inputs in enumerate(test_loader):\n",
    "        inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            predictions.append(sfm(outputs)) ## ADD SOFTMAX\n",
    "    predictions = np.concatenate([t.cpu().numpy() for t in predictions])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_dataset = SpectrogramTestDataset([[path, None] for path in sample_subm.image_fn.values ], conf)\n",
    "subm_loader = torch.utils.data.DataLoader(subm_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/letfoolsdie/virtual_envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 658 ms, total: 14.1 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds = get_predictions(model_ft, subm_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 193)\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1017, 195)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_subm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.6 ms, sys: 502 s, total: 38.1 ms\n",
      "Wall time: 37.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for c in sample_subm.columns:\n",
    "    if c in {\"fn\", \"image_fn\"}:\n",
    "        continue\n",
    "    c_idx = label2code[c]\n",
    "    sample_subm[c] = preds[:, c_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>maize streak virus</th>\n",
       "      <th>disease</th>\n",
       "      <th>okukkoola</th>\n",
       "      <th>muwogo</th>\n",
       "      <th>mpeke</th>\n",
       "      <th>mucungwa</th>\n",
       "      <th>greens</th>\n",
       "      <th>garden</th>\n",
       "      <th>mango</th>\n",
       "      <th>...</th>\n",
       "      <th>suckers</th>\n",
       "      <th>insects</th>\n",
       "      <th>fertilizer</th>\n",
       "      <th>nakavundira</th>\n",
       "      <th>ekiwojjolo</th>\n",
       "      <th>akawuka</th>\n",
       "      <th>ddagala</th>\n",
       "      <th>ebiwojjolo</th>\n",
       "      <th>obutungulu</th>\n",
       "      <th>image_fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1014</td>\n",
       "      <td>audio_files/ZSC69U3.wav</td>\n",
       "      <td>8.149199e-07</td>\n",
       "      <td>1.292392e-07</td>\n",
       "      <td>1.112196e-07</td>\n",
       "      <td>4.493209e-08</td>\n",
       "      <td>2.958854e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.251234e-07</td>\n",
       "      <td>4.019745e-07</td>\n",
       "      <td>6.517575e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>8.830582e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>3.836421e-07</td>\n",
       "      <td>/home/letfoolsdie/zindi_nlp/data/all_audio_res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1015</td>\n",
       "      <td>audio_files/ZU1I8MR.wav</td>\n",
       "      <td>1.874003e-06</td>\n",
       "      <td>8.202001e-06</td>\n",
       "      <td>1.476747e-05</td>\n",
       "      <td>1.142804e-03</td>\n",
       "      <td>1.334780e-04</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>9.299334e-06</td>\n",
       "      <td>3.541032e-06</td>\n",
       "      <td>4.387319e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.208195e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>1.925283e-03</td>\n",
       "      <td>/home/letfoolsdie/zindi_nlp/data/all_audio_res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1016</td>\n",
       "      <td>audio_files/ZYO56VD.wav</td>\n",
       "      <td>8.708632e-06</td>\n",
       "      <td>2.683408e-06</td>\n",
       "      <td>4.515495e-07</td>\n",
       "      <td>7.280465e-08</td>\n",
       "      <td>8.039318e-06</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.066791e-06</td>\n",
       "      <td>2.629088e-06</td>\n",
       "      <td>4.681643e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.856069e-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.531623e-08</td>\n",
       "      <td>/home/letfoolsdie/zindi_nlp/data/all_audio_res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           fn  maize streak virus       disease     okukkoola  \\\n",
       "1014  audio_files/ZSC69U3.wav        8.149199e-07  1.292392e-07  1.112196e-07   \n",
       "1015  audio_files/ZU1I8MR.wav        1.874003e-06  8.202001e-06  1.476747e-05   \n",
       "1016  audio_files/ZYO56VD.wav        8.708632e-06  2.683408e-06  4.515495e-07   \n",
       "\n",
       "            muwogo         mpeke  mucungwa        greens        garden  \\\n",
       "1014  4.493209e-08  2.958854e-07  0.000002  3.251234e-07  4.019745e-07   \n",
       "1015  1.142804e-03  1.334780e-04  0.000486  9.299334e-06  3.541032e-06   \n",
       "1016  7.280465e-08  8.039318e-06  0.000019  1.066791e-06  2.629088e-06   \n",
       "\n",
       "             mango  ...   suckers       insects  fertilizer  nakavundira  \\\n",
       "1014  6.517575e-07  ...  0.000001  8.830582e-07    0.000002     0.000025   \n",
       "1015  4.387319e-06  ...  0.000002  2.208195e-05    0.000008     0.000115   \n",
       "1016  4.681643e-06  ...  0.000007  4.856069e-06    0.000005     0.000001   \n",
       "\n",
       "      ekiwojjolo   akawuka   ddagala  ebiwojjolo    obutungulu  \\\n",
       "1014    0.000051  0.000011  0.000012    0.000051  3.836421e-07   \n",
       "1015    0.000610  0.000055  0.000002    0.003195  1.925283e-03   \n",
       "1016    0.000013  0.000012  0.000204    0.000002  1.531623e-08   \n",
       "\n",
       "                                               image_fn  \n",
       "1014  /home/letfoolsdie/zindi_nlp/data/all_audio_res...  \n",
       "1015  /home/letfoolsdie/zindi_nlp/data/all_audio_res...  \n",
       "1016  /home/letfoolsdie/zindi_nlp/data/all_audio_res...  \n",
       "\n",
       "[3 rows x 195 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_subm.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_subm.drop(\"image_fn\", axis=1).to_csv('submissions/simple_kaggle_custom_spects.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
